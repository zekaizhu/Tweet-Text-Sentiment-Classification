{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zazhu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/zazhu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from io import StringIO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import fasttext\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/Corona_NLP_train.csv\",encoding='latin1')\n",
    "test = pd.read_csv(\"../data/Corona_NLP_test.csv\",encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>3794</td>\n",
       "      <td>48746</td>\n",
       "      <td>Israel ??</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3795</td>\n",
       "      <td>48747</td>\n",
       "      <td>Farmington, NM</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3796</td>\n",
       "      <td>48748</td>\n",
       "      <td>Haverford, PA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>3797</td>\n",
       "      <td>48749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>3798</td>\n",
       "      <td>48750</td>\n",
       "      <td>Arlington, Virginia</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserName  ScreenName             Location     TweetAt  \\\n",
       "0            1       44953                  NYC  02-03-2020   \n",
       "1            2       44954          Seattle, WA  02-03-2020   \n",
       "2            3       44955                  NaN  02-03-2020   \n",
       "3            4       44956          Chicagoland  02-03-2020   \n",
       "4            5       44957  Melbourne, Victoria  03-03-2020   \n",
       "...        ...         ...                  ...         ...   \n",
       "3793      3794       48746            Israel ??  16-03-2020   \n",
       "3794      3795       48747       Farmington, NM  16-03-2020   \n",
       "3795      3796       48748        Haverford, PA  16-03-2020   \n",
       "3796      3797       48749                  NaN  16-03-2020   \n",
       "3797      3798       48750  Arlington, Virginia  16-03-2020   \n",
       "\n",
       "                                          OriginalTweet           Sentiment  \n",
       "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1     When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2     Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3     #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
       "...                                                 ...                 ...  \n",
       "3793  Meanwhile In A Supermarket in Israel -- People...            Positive  \n",
       "3794  Did you panic buy a lot of non-perishable item...            Negative  \n",
       "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral  \n",
       "3796  Gov need to do somethings instead of biar je r...  Extremely Negative  \n",
       "3797  I and @ForestandPaper members are committed to...  Extremely Positive  \n",
       "\n",
       "[3798 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive              0.277523\n",
       "Negative              0.240955\n",
       "Neutral               0.187404\n",
       "Extremely Positive    0.160945\n",
       "Extremely Negative    0.133173\n",
       "Name: Sentiment, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'] = train.OriginalTweet\n",
    "train[\"text\"] = train[\"text\"].astype(str)\n",
    "\n",
    "test['text'] = test.OriginalTweet\n",
    "test[\"text\"] = test[\"text\"].astype(str)\n",
    "\n",
    "# Data has 5 classes\n",
    "train.Sentiment.value_counts(normalize= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName            0\n",
       "ScreenName          0\n",
       "Location         8590\n",
       "TweetAt             0\n",
       "OriginalTweet       0\n",
       "Sentiment           0\n",
       "text                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName           0\n",
       "ScreenName         0\n",
       "Location         834\n",
       "TweetAt            0\n",
       "OriginalTweet      0\n",
       "Sentiment          0\n",
       "text               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    '''tokenize and normalize'''\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    # convert to dataframe\n",
    "    data = pd.DataFrame({'text': x.text, 'label': x.Sentiment})\n",
    "\n",
    "    # remove html\n",
    "    data['text'] = data.apply(lambda t: re.sub(r'https?://\\S+|www\\.\\S+', '', str(t['text'])), axis=1)\n",
    "\n",
    "    # remove stopwords, number, and convert to lower case\n",
    "    data['text'] = data.apply(lambda r: ' '.join(w.lower() for w in r['text'].split() if (w.lower() not in stop_words) & (w.isalpha())),axis=1)\n",
    "    data['text'] = data[data['text'] != '']\n",
    "    \n",
    "    # discard NA reviews\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "train_new = preprocess(train)\n",
    "test_new = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.88795477252236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.text.apply(lambda x: len(x)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice talk neighbours family exchange phone n...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus woolworths give disabled dedicated...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food stock one enough food everyone take stay ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ready go supermarket food stock litteraly seri...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>news first confirmed case came sullivan county...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text               label\n",
       "1  advice talk neighbours family exchange phone n...            Positive\n",
       "2  coronavirus woolworths give disabled dedicated...            Positive\n",
       "3  food stock one enough food everyone take stay ...            Positive\n",
       "4  ready go supermarket food stock litteraly seri...  Extremely Negative\n",
       "5  news first confirmed case came sullivan county...            Positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = (1,2)\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,ngram_range=ngram, stop_words='english')\n",
    "tfidf.fit_transform(train_new.text.values)\n",
    "\n",
    "# We transform each text into a vector\n",
    "x_train = tfidf.transform(train_new.text.values)\n",
    "x_test = tfidf.transform(test_new.text.values)\n",
    "y_train = train_new.label.values\n",
    "y_test = test_new.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best performing svm model\n",
    "with open('tfidf_vec.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5004\n",
      "Micro-averaged F1 score: 0.5004\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(random_state=66,solver='lbfgs')  # fit logistic\n",
    "lr1.fit(x_train, y_train)\n",
    "y_pred = lr1.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5036\n",
      "Micro-averaged F1 score: 0.5036\n"
     ]
    }
   ],
   "source": [
    "lr2 = LogisticRegression(random_state=66, C=15, penalty='l2',solver='lbfgs')  # fit logistic\n",
    "lr2.fit(x_train, y_train)\n",
    "y_pred = lr2.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5104\n",
      "Micro-averaged F1 score: 0.5104\n"
     ]
    }
   ],
   "source": [
    "lr3 = LogisticRegression(random_state=66, C=10, penalty='l2',solver='lbfgs')\n",
    "lr3.fit(x_train, y_train)\n",
    "y_pred = lr3.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4714\n",
      "Micro-averaged F1 score: 0.4714\n"
     ]
    }
   ],
   "source": [
    "lr4 =LogisticRegression(random_state=66, C=15, penalty='l2',solver='liblinear')\n",
    "lr4.fit(x_train, y_train)\n",
    "y_pred = lr4.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5210\n",
      "Micro-averaged F1 score: 0.5210\n"
     ]
    }
   ],
   "source": [
    "lr5 = LogisticRegression(random_state=66, C=2, penalty='l1',solver='liblinear')\n",
    "lr5.fit(x_train, y_train)\n",
    "y_pred = lr5.predict(x_test) # predict\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7829\n"
     ]
    }
   ],
   "source": [
    "# fasttext requires data to be in the format of: __label__1 text\n",
    "train_fasttext = train_new.apply(lambda t: '__label__' + str(t['label']) + ' ' + str(t['text']), axis=1)\n",
    "test_fasttext = test_new.apply(lambda t: '__label__' + str(t['label']) + ' ' + str(t['text']), axis=1)\n",
    "train_fasttext.to_csv('fasttext_train.txt',index=False, header=False)\n",
    "test_fasttext.to_csv('fasttext_test.txt',index=False, header=False)\n",
    "\n",
    "# fasttext model - default\n",
    "ft_model1 = fasttext.train_supervised('fasttext_train.txt')\n",
    "\n",
    "# calculate evaluation metrics\n",
    "result = ft_model1.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7642\n"
     ]
    }
   ],
   "source": [
    "# fasttext model - setting 1\n",
    "ft_model2 = fasttext.train_supervised('fasttext_train.txt',wordNgrams=2)\n",
    "result = ft_model2.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7629\n"
     ]
    }
   ],
   "source": [
    "# fasttext model - setting 2\n",
    "ft_model3 = fasttext.train_supervised('fasttext_train.txt',lr=0.2, wordNgrams=2)\n",
    "result = ft_model3.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7586\n"
     ]
    }
   ],
   "source": [
    "# fasttext model - setting 3\n",
    "ft_model4 = fasttext.train_supervised('fasttext_train.txt', lr=0.5, wordNgrams=2)\n",
    "result = ft_model4.test('fasttext_test.txt')\n",
    "precision = result[1]\n",
    "recall = result[2]\n",
    "print(\"F1 score: %0.4f\"%(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4730\n",
      "Micro-averaged F1 score: 0.4730\n"
     ]
    }
   ],
   "source": [
    "svm1 = LinearSVC(random_state=66)\n",
    "svm1.fit(x_train, y_train)\n",
    "y_pred = svm1.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4495\n",
      "Micro-averaged F1 score: 0.4495\n"
     ]
    }
   ],
   "source": [
    "svm2 = LinearSVC(random_state=66, penalty='l2', C=10, loss='hinge')\n",
    "svm2.fit(x_train, y_train)\n",
    "y_pred = svm2.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4727\n",
      "Micro-averaged F1 score: 0.4727\n"
     ]
    }
   ],
   "source": [
    "svm3 = LinearSVC(random_state=66, penalty='l2', loss='squared_hinge', dual=False)\n",
    "svm3.fit(x_train, y_train)\n",
    "y_pred = svm3.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4996\n",
      "Micro-averaged F1 score: 0.4996\n"
     ]
    }
   ],
   "source": [
    "svm4 = LinearSVC(random_state=66, penalty='l1', loss='squared_hinge', dual=False)\n",
    "svm4.fit(x_train, y_train)\n",
    "y_pred = svm4.predict(x_test)\n",
    "\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight='balanced', max_depth=50, n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "max_depth = [10,30,50]\n",
    "n_estimators = [200,500]\n",
    "grid_params ={'max_depth':max_depth,'n_estimators':n_estimators}\n",
    "\n",
    "RandomFoest_model = GridSearchCV(RandomForestClassifier(class_weight = 'balanced'), grid_params,\n",
    "                  scoring = 'accuracy', cv=5,n_jobs=-1, return_train_score=True)\n",
    "RandomFoest_model.fit(x_train, y_train)\n",
    "\n",
    "results = pd.DataFrame.from_dict(RandomFoest_model.cv_results_)\n",
    "print(RandomFoest_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4289\n",
      "Micro-averaged F1 score: 0.4289\n"
     ]
    }
   ],
   "source": [
    "RandomFoest_model = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
    "                                      max_depth=50, n_estimators=200,  random_state=66, verbose=0)\n",
    "RandomFoest_model.fit(x_train,y_train)\n",
    "\n",
    "y_pred = RandomFoest_model.predict(x_test)\n",
    "print(\"Accuracy: %0.4f\"%accuracy_score(y_test, y_pred))\n",
    "print(\"Micro-averaged F1 score: %0.4f\"%f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store best model\n",
    "ft_model1.save_model('fasttext_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"0__label: Extremely Negative\": {\n",
      "    \"predicted label\": \"__label__Neutral\",\n",
      "    \"Probability\": 0.9999134540557861\n",
      "  },\n",
      "  \"1__label: Extremely Positive\": {\n",
      "    \"predicted label\": \"__label__Positive\",\n",
      "    \"Probability\": 0.9997422099113464\n",
      "  },\n",
      "  \"2__label: Negative\": {\n",
      "    \"predicted label\": \"__label__Negative\",\n",
      "    \"Probability\": 0.8929682970046997\n",
      "  },\n",
      "  \"3__label: Neutral\": {\n",
      "    \"predicted label\": \"__label__Negative\",\n",
      "    \"Probability\": 0.9983593225479126\n",
      "  },\n",
      "  \"4__label: Positive\": {\n",
      "    \"predicted label\": \"__label__Positive\",\n",
      "    \"Probability\": 0.999428391456604\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# read fasttext model and tfidf tranformer\n",
    "loaded_model = fasttext.load_model('model/fasttext_model')\n",
    "\n",
    "comment = ['I HATE COVID',\n",
    "        'Stay strong and we can make it!',\n",
    "        \"It's fucking horrible that I can't even breath inside the mask.\",\n",
    "        'Life is bad but we have to stay at home.',\n",
    "        'Life will be better when the vaccine comes out.']\n",
    "\n",
    "label = ['Extremely Negative', 'Extremely Positive', 'Negative', 'Neutral', 'Positive']\n",
    "\n",
    "\n",
    "result = {}\n",
    "for i in range(len(label)):\n",
    "    predict = loaded_model.predict(comment[i])\n",
    "    result[str(i) + '__label: ' + str(label[i])] = {'predicted label': predict[0][0],\n",
    "                                           'Probability': predict[1][0]}\n",
    "\n",
    "# save results\n",
    "with open('predcition.json', 'w') as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
